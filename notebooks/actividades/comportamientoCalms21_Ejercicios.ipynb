{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gastonbujia/curso-visualizacion-datos-SAN-2022/blob/main/notebooks/actividades/comportamientoCalms21_Ejercicios.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "nJdtN4pA2Osf"
      },
      "source": [
        "<h1>\n",
        "CalMS21: Caltech Mouse Social Interaction Dataset 2021 \n",
        "</h1>\n",
        "\n",
        "Esta notebook es una adaptaci贸n de la provista por NeuroMatch Academy durante la escuela de [Computational Neuroscience](https://compneuro.neuromatch.io/tutorials/intro.html) curada por Ann Kenedy, que a su vez es una adapataci贸n de la que fuera creada por Dipam Chakraborty y Sharada Mohanty de AIcrowd para el <a href=https://www.aicrowd.com/challenges/multi-agent-behavior-representation-modeling-measurement-and-applications>Multi-Agent Behavior Challenge</a>. La notebook original puede ser encontrada en este [link](https://compneuro.neuromatch.io/projects/behavior/README.html).\n",
        "\n",
        "Este [dataset](https://data.caltech.edu/records/s0vdx-0k302) tiene estimaciones de pose-tracking de ratones interactuando socialmente mediante capturas de video y adem谩s cuenta con anotaciones sobre 3 posibles interacciones sociales: *investigacion*, *montar* y *atacar* separada de *otros* compartamientos.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "gRqv3qRZ2Osi"
      },
      "source": [
        "# Imports e instalaciones \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "P9eRbsyi2Osl"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Algunas librerias para graficar\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "\n",
        "# Seteamos el estilo\n",
        "sns.set(style=\"darkgrid\")\n",
        "\n",
        "# Reducci贸n de la dimensi贸n y otros\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset CalMS21 \n",
        "\n",
        "El dataset **CalMS21** esta hosteado y mantenido por Caltech en https://data.caltech.edu/records/1991. Brevemente, CalMS21 contiene videos y datos anotados de una tarea experimental en la cual se estudia el comportamiento social entre dos ratones, uno que es residente del ambiente y un segundo que es introducido en el mismo. Las interacciones duran aproximadamente unos 10 minutos, son grabadas en un plano cenital y se anotan los comportamientos registrados durante ese tiempo. De los videos se extraen 7 puntos (`keypoints`) para cada rat贸n estimados por un red neuronal y una confianza de la localizaci贸n de estos puntos.\n",
        "\n",
        "![](https://images.aicrowd.com/uploads/ckeditor/pictures/332/content_expt_setup_merged.gif)\n",
        "\n",
        "Pueden encontrar [ac谩](https://www.youtube.com/watch?v=tDmhmasjPeM) un video donde una de las autoras del trabajo nos cuenta sobre este dataset.\n",
        "\n",
        "Dado que el dataset fue construido con el objetivo de probar t茅cnicas de Machine Learning y Deep Learning, hay m谩s de una tarea expermiental, y cada una de ellas contar谩 con un conjunto de *entrenamiento*(`train`) y de *evaluaci贸n*(`test`). En esta notebook solo usaremos los datos anotados como la *tarea 1* (`task1`) y el conjunto de entrenamiento. "
      ],
      "metadata": {
        "id": "Bz4q_fR6hj1M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "f1jOx1MS2Osq",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Descarga y unzip\n",
        "import os, requests, zipfile\n",
        "\n",
        "# Descargamos los datos a colab\n",
        "fname = 'task1_classic_classification.zip'\n",
        "url = \"https://data.caltech.edu/records/s0vdx-0k302/files/task1_classic_classification.zip?download=1\"\n",
        "\n",
        "if not os.path.isfile(fname):\n",
        "  try:\n",
        "    r = requests.get(url)\n",
        "  except requests.ConnectionError:\n",
        "    print(\"!!! Failed to download data !!!\")\n",
        "  else:\n",
        "    if r.status_code != requests.codes.ok:\n",
        "      print(\"!!! Failed to download data !!!\")\n",
        "    else:\n",
        "      with open(fname, \"wb\") as fid:\n",
        "        fid.write(r.content)\n",
        "else:\n",
        "  print('Data have already been downloaded!!!')\n",
        "\n",
        "if not os.path.exists('task1_classic_classification'):\n",
        "  # Unzip the file\n",
        "  with zipfile.ZipFile(fname, 'r') as zip_ref:\n",
        "    zip_ref.extractall('.')\n",
        "\n",
        "# Descargamos el parser\n",
        "fname = 'calms21_convert_to_npy.py'\n",
        "url = \"https://data.caltech.edu/records/s0vdx-0k302/files/calms21_convert_to_npy.py?download=1\"\n",
        "\n",
        "if not os.path.isfile(fname):\n",
        "  try:\n",
        "    r = requests.get(url)\n",
        "  except requests.ConnectionError:\n",
        "    print(\"!!! Failed to download data !!!\")\n",
        "  else:\n",
        "    if r.status_code != requests.codes.ok:\n",
        "      print(\"!!! Failed to download data !!!\")\n",
        "    else:\n",
        "      with open(fname, \"wb\") as fid:\n",
        "        fid.write(r.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "RaNAHKSw2Oss"
      },
      "source": [
        "Los archivos del conjunto de datos se almacenan como archivos json. Para facilitar el manejo, primero los convertiremos a archivos .npy usando el script que acabamos de descargar, `calms21_convert_to_npy.py`. La salida de este script es un par de archivos, `calms21_task1_train.npy` y `calms21_task1_test.npy`. Como nosotros no vamos a intentar hacer predicciones con estos datos sino un an谩lisis exploratorio.\n",
        "\n",
        "El repositorio cuenta con un script `calms21_convert_to_npy.py` que permite convertir los datos que estan en formato `JSON` a un formato que nos permite leerlo m谩s facilmente: NumPy Array. En la pr贸xima celda mostramos como utilizar el script pasandole los directorios donde se almacenaron los datos descargados. Si se incluye el indicador `parse_treba` opcional, el script crear谩 los archivos `calms21_task1_train_features.npy` y `calms21_task1_test_features.npy`, que contienen unos 60 *features* creadas con <a href=https://openaccess.thecvf.com/content/CVPR2021/html/Sun_Task_Programming_Learning_Data_Efficient_Behavior_Representations_CVPR_2021_paper.html>Task Programming</a>. Mas adelante tambi茅n exploraremos esta informaci贸n.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "NdflG4zj2Osu",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Ejecutar celda para extraer y crear los archivos necesarios\n",
        "!python calms21_convert_to_npy.py  --input_directory '.' --output_directory '.'\n",
        "!python calms21_convert_to_npy.py  --input_directory '.' --output_directory '.' --parse_treba"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "rrk6PPMG2Osw"
      },
      "source": [
        "# Cargamos la data \n",
        "A continuaci贸n proveemos una funci贸n que permite cargar los datos. Si quieren exploren y traten de entender que es lo que hace."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "u-hmD8z-2Osx"
      },
      "outputs": [],
      "source": [
        "def load_task1_data(data_path, features_path):\n",
        "  \"\"\"\n",
        "  Cargar datos para la tarea 1:\n",
        "       El vocabulario le dice c贸mo asignar nombres de comportamiento a identificadores de clase;\n",
        "       es el mismo para todas las secuencias en este conjunto de datos.\n",
        "  \"\"\"\n",
        "  data_dict = np.load(data_path, allow_pickle=True).item()\n",
        "  dataset = data_dict['annotator-id_0']\n",
        "  # Obtener una secuencia y sus llaves.\n",
        "  sequence_id = list(data_dict['annotator-id_0'].keys())[0]\n",
        "  vocabulary = data_dict['annotator-id_0'][sequence_id]['metadata']['vocab']\n",
        "  features = np.load(features_path, allow_pickle=True).item()['annotator-id_0']\n",
        "  return dataset, features, vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "pFVJ2jp32Os0"
      },
      "outputs": [],
      "source": [
        "training_data, training_features, vocab = load_task1_data('./calms21_task1_train.npy', './calms21_task1_train_features.npy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "51dU2_bT2Os2"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "Las variables reci茅n creadas `training_data` y `test_data` son diccionarios con una clave para cada **Secuencia** en el conjunto de datos, donde una **Secuencia** es un 煤nico ensayo residente-intruso, *hay un total de 70 ensayos*. Cada **Secuencia** contiene los siguientes campos:\n",
        "\n",
        "<ul>\n",
        "<li><b>keypoints</b>: ubicaciones rastreadas de partes del cuerpo en los dos ratones que interact煤an. Estos se producen utilizando una red de reloj de arena apilado entrenada en 15,000 marcos etiquetados a mano.\n",
        "<ul>\n",
        "<li>Dimensiones: (n.潞 de fotogramas) x (ID del rat贸n) x (coordenada x, y) x (parte del cuerpo).\n",
        "<li>Unidades: p铆xeles; las coordenadas son relativas a la imagen completa. Las dimensiones de la imagen original son 1024 x 570.\n",
        "</ul>\n",
        "<li><b>scores</b>: estimaciones de confianza para los puntos clave rastreados.\n",
        "<ul>\n",
        "<li>Dimensiones: (n.潞 de fotogramas) x (ID del rat贸n) x (parte del cuerpo).\n",
        "<li>Unidades: sin unidades, rango de 0 (confianza m谩s baja) a 1 (confianza m谩s alta).\n",
        "</ul>\n",
        "<li> <b>annotations</b>: ID de comportamientos como un n煤mero entero anotado en cada cuadro por un experto en el dominio. Consulte a continuaci贸n las asignaciones de ID de comportamiento a nombre de comportamiento.\n",
        "<ul>\n",
        "<li>Dimensiones: (# cuadros) .\n",
        "</ul>\n",
        "<li><b>metadata</b>: los metadatos registrados son annotator_id, que se representa mediante un int, y el vocabulario, que contiene un diccionario que asigna nombres de comportamiento a identificadores enteros en las anotaciones.\n",
        "</ul>\n",
        "\n",
        "El archivo 'taskprog_features' contiene el campo adicional:\n",
        "\n",
        "<ul>\n",
        "<li><b>features</b>: caracter铆sticas precalculadas de un modelo entrenado con programaci贸n de tareas en los datos de trayectoria del conjunto de videos sin etiqueta CalMS21.\n",
        "<ul>\n",
        "<li>Dimensiones: (n.潞 de fotogramas) x (dimensi贸n caracter铆stica = 32).\n",
        "</li>\n",
        "</ul>\n",
        "</ul>\n",
        "\n",
        "![](https://images.aicrowd.com/uploads/ckeditor/pictures/337/content_keypoints_task_1.png)\n",
        "\n",
        "<b>NOTA:</b> para todos los puntos clave, el rat贸n 0 es el rat贸n residente (negro) y el rat贸n 1 es el rat贸n intruso (blanco). Hay 7 partes del cuerpo rastreadas, ordenadas (nose, left ear, right ear, neck, left hip, right hip, tail base)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "btO01qQ72Os5"
      },
      "source": [
        "## 驴C贸mo se ven los datos? \n",
        "\n",
        "### Resumen de datos\n",
        "\n",
        "Como se describi贸 anteriormente, nuestro conjunto de datos consta de diccionarios de Secuencias y un vocabulario adjunto que nos dice qu茅 comportamiento es resgistrado con que c贸digo num茅rico:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "kKWncUKl2Os6"
      },
      "outputs": [],
      "source": [
        "print(\"Algunas keys: \", list(training_data.keys())[:3])\n",
        "print(\"Vocabulario: \", vocab)\n",
        "print(\"Numero de secuencias: \", len(training_data))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Veamos en que formato esta y que tipos tienen para ver si podemos cargarlo facilmente a Pandas\n",
        "print(f\"Tipo de training data: {type(training_data)}\")\n",
        "print(f\"Tipo de cada dato de un ensayo: {type(training_data['task1/train/mouse001_task1_annotator1'])}\")\n",
        "sequence_names = list(training_data.keys())\n",
        "sample_sequence_key = sequence_names[0]\n",
        "single_sequence = training_data[sample_sequence_key]\n",
        "print(\"Nombre de nuestra secuencia: \", sample_sequence_key)\n",
        "print(\"Keys de la secuencia: \", single_sequence.keys())\n",
        "print(\"Metadata: \", single_sequence['metadata'])\n",
        "print(f\"Numero de frames en una secuencia \\\"{sample_sequence_key}\\\": \", len(single_sequence['annotations']))\n",
        "print(f\"Tama帽o de los keypoints de una secuencia \\\"{sample_sequence_key}\\\": \", single_sequence['keypoints'].shape)"
      ],
      "metadata": {
        "id": "4lCWxSNfmlCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "No parece ser tan f谩cil cargarlo directamente en un DataFrame de Pandas, pero pueden intentarlo en la pr贸xima celda a ver que sucede..."
      ],
      "metadata": {
        "id": "wpx4SfCfGjcs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# COMPLETAR pasarlo directamente a dataframe e imprimirlo\n",
        "df = ...\n",
        "df"
      ],
      "metadata": {
        "id": "KQ6rKrv2m0UV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "驴Tiene sentido cargarlo de esta manera? 驴Que representa cada una de las dimensiones de dataframe cargado de esta manera?"
      ],
      "metadata": {
        "id": "820f87jHrn5B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejercicio 1: Explorando narices "
      ],
      "metadata": {
        "id": "Eamd2nar8FCC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hay varias preguntas que nos pueden interesar a la hora de estudiar este conjunto de datos que tiene que ver con describir las posiciones del cuerpo de los ratones seg煤n cada comportamiento. Para este ejercicio nos va a interesar explorar que pasa con las narices de los ratones en cada comportamiento para el primer ensayo."
      ],
      "metadata": {
        "id": "5930lNe7DFPX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Nos vamos para Pandas! \n",
        "\n",
        "a) Como vimos reci茅n vamos a tener que trabajar un poco el dataset para poder cargarlo en Pandas, por eso primero tienen que completar la funci贸n de abajo que procesa uno de los ensayos y nos devuelve toda la informaci贸n en un unico dataframe. *Hint:* Mirar la funci贸n `pd.concat` "
      ],
      "metadata": {
        "id": "ycBfyxN1MHC1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# COMPLETAR esta funci贸n para que procese el diccionario de anotaciones en un solo dataframe donde cada columna va a ser una coordenada de un keypoint de cada raton y la confianza\n",
        "def load_annotator_df(data_dict, annotator):\n",
        "    \n",
        "    # vamos a trabajar solo con un ensayo\n",
        "    dict_aux = data_dict[annotator]\n",
        "    # vocabulario\n",
        "    annot_keys = {0:'attack',1: 'investigation',2: 'mount',3:'other'}\n",
        "    # nombre de los keypoints\n",
        "    body_parts = [\"nose\", \"left_ear\", \"right_ear\", \"neck\", \"left_hip\", \"right_hip\", \"tail_base\"]\n",
        "    # una lista donde iremos dejando cada dataframe para luego unirlos en un unico dataframe\n",
        "    df_list = []\n",
        "    \n",
        "    # desagregamos los keypoints en columnas para cada parte trackeada / aclarar aca que podemos tambien usar una lista por comprension / reemplazar por lista\n",
        "    df_list.append(pd.DataFrame(dict_aux['keypoints'][:,0,0,:] , dtype=float, columns=['keypoints_mousse_resident_x_'+i for i in body_parts]))\n",
        "    df_list.append(pd.DataFrame(dict_aux['keypoints'][:,0,1,:] , dtype=float, columns=['keypoints_mousse_resident_y_'+i for i in body_parts]))\n",
        "    df_list.append(pd.DataFrame(dict_aux['keypoints'][:,1,0,:] , dtype=float, columns=['keypoints_mousse_intruder_x_'+i for i in body_parts]))\n",
        "    df_list.append(pd.DataFrame(dict_aux['keypoints'][:,1,1,:] , dtype=float, columns=['keypoints_mousse_intruder_y_'+i for i in body_parts]))\n",
        "    \n",
        "    # desagregamos la confianza de los keypoints \n",
        "    df_list.append(pd.DataFrame(dict_aux['scores'][:,0,:] , dtype=float, columns=['keypoints_mousse_resident_confidence_'+i for i in body_parts]))\n",
        "    df_list.append(pd.DataFrame(dict_aux['scores'][:,1,:] , dtype=float, columns=['keypoints_mousse_intruder_confidence_'+i for i in body_parts]))\n",
        "\n",
        "    # COMPLETAR: crear un 煤nico dataframe que sea el resultado de concatenar todos los dataframes de la lista df_list que contenga todas las columnas\n",
        "    df = ...\n",
        "\n",
        "    # COMPLETAR: agregar al dataframe recien creado una columna con la etiqueta correspondiente\n",
        "    df['annotations'] = ...\n",
        "\n",
        "    # COMPLETAR: reemplazar la columna annotations por una que codifique el comportamiento anotado en el vocabulario (miren la funcin map de pandas)\n",
        "    df['annotations'] = ...\n",
        "    \n",
        "    return df"
      ],
      "metadata": {
        "id": "ljzzUU9kp7vo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = load_annotator_df(training_data, 'task1/train/mouse001_task1_annotator1')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "S5cSD0-rNdG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "b) 驴Que comportamientos se registraron para este ensayo?"
      ],
      "metadata": {
        "id": "VLjeto-ORv_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# COMPLETAR Imprimir los valores unicos de la columna annotations\n",
        "..."
      ],
      "metadata": {
        "id": "TfYlknKrRvg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Nuevas columnas\n",
        "\n",
        "Vamos a crear algunas columnas a partir del dataframe cargado que nos permitan caracterizar los comportamientos encontrados en este ensayo y nos basaremos en las distancais de las narices!\n"
      ],
      "metadata": {
        "id": "rc9eiqrGNd-t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "a) Para esto queremos mirar los frames que esten bien estimados, vamos a quedarnos solo con aquellos que tienen una estimaci贸n de la nariz m谩s alta que 0.5. Primero seleccionen y grafiquen la distribuci贸n de esa confianza para las narices para ambos ratones con un histograma conjunto (o pueden usar dos). *Hint* Pueden usar el par谩metro `alpha` que controla la transparencia de las barras."
      ],
      "metadata": {
        "id": "SPUZq9ZbNs6b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# COMPLETAR: Graficar la distribuci贸n de la confianza de los keypoints estimate para la nariz de cada raton\n",
        "..."
      ],
      "metadata": {
        "id": "RbyFnnh1OqdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "b) Filtren el dataset en base a que ambas columnas sean mayor al corte `thres`. *Hint* Al tener mas de una condici贸n, dependiendo de que quieran hacer las puede servir el comando [`all`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.all.html)"
      ],
      "metadata": {
        "id": "mQIVP2jaRLEO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# COMPLETAR Crear una mascara con el punto de corte y crear un nuevo dataset a partir de ese\n",
        "cols = [\"keypoints_mousse_resident_confidence_nose\", \"keypoints_mousse_intruder_confidence_nose\"]\n",
        "thres = 0.5\n",
        "df_filter = ...\n",
        "\n",
        "# PREGUNTA: Cuantos datos tiraron?\n",
        "total_frames  = df.shape[0]\n",
        "total_tirados = ...\n",
        "print(f'Descartamos un total del {...}% de frames')"
      ],
      "metadata": {
        "id": "Ucj0mdWm3il-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "c) Ahora si podemos pensar en crear la columna que mida la distancia entre las narices de ambos ratones. Para eso podemos calcular la distancia eucl铆dea entre dos puntos de coordenadas $(x_0,y_0)$ y $(x_1,y_1)$ como:\n",
        "\n",
        "$d=\\sqrt{(x_1-x_0)^2+(y_1-y_0)^2}$\n",
        "\n",
        "\n",
        "Usen las funciones estandar de numpy `sqrt` y `**` para calcularla. PpPpueden usar el atributo `.values` para restar varias columnas entre si. Como adicional vean como pueden calcularla usando la norma del vector restado de las dos narices: [np.linalg.norm](https://numpy.org/doc/stable/reference/generated/numpy.linalg.norm.html)."
      ],
      "metadata": {
        "id": "xdIa29imP7FA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# COMPLETAR: Crear una nueva columna que mida la distancia entre las narices de los ratones\n",
        "df_filter[\"distance_nose\"] = ...\n"
      ],
      "metadata": {
        "id": "DW1ahHd73Rhf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "d) Finalmente graficar en un violinplot la distribuci贸n de la columna nueva para cada comportamiento registrado."
      ],
      "metadata": {
        "id": "kppSKwXfSTyd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# COMPLETAR: Graficar para cada comportamiento registrado la distribuci贸n de estas distancias (usar un violinplot)\n",
        "..."
      ],
      "metadata": {
        "id": "tkgdonvJSTfC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 Correlaciones de movimiento"
      ],
      "metadata": {
        "id": "vh53RiVoQrCK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por 煤ltimo podemos ver que sucede con la correlaci贸n entre las columnas dependiendo de cada comportamiento. Para eso vamos a seleccionar las columnas asociadas a cada punto del cuerpo en el dataframe filtrado y crear nuevas columnas distancia entre ellos y ver si existe correlaciones entre ellas durante la etiqueta `mount`."
      ],
      "metadata": {
        "id": "fi6iKgEFQyVH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vamos a seleccionar las columnas y crear las de distancia \n",
        "body_parts    = [\"nose\", \"left_ear\", \"right_ear\", \"neck\", \"left_hip\", \"right_hip\", \"tail_base\"]\n",
        "cols_intruder = [f\"keypoints_mousse_intruder_{coord}_\"+part for coord in [\"x\",\"y\"] for part in body_parts ] # esto es lo que se conoce como lista por comprehension\n",
        "cols_resident = [f\"keypoints_mousse_resident_{coord}_\"+part for coord in [\"x\",\"y\"] for part in body_parts ]\n",
        "# Hacemos la diferencia coordenada a coordenada\n",
        "diff_array    = df_filter[cols_intruder].values-df_filter[cols_resident].values\n",
        "print(diff_array.shape)\n",
        "\n",
        "# Diff ahora tiene las diferencias coordenada a coordenada, nos falta recorrer las partes del cuerpo y calcular la norma vectorial para obtener las distnacias\n",
        "for i, part in enumerate(body_parts): # enumerate nos devuelve una tupla (i, part) donde el i es la enumeraci贸n de los objetos que hay dentro de la lista\n",
        "    df_filter[f\"distance_{part}\"] = np.linalg.norm(diff_array[:,[i,i+7]],axis=1) # 7 porque las columnas son las 7 partes del cuerpo"
      ],
      "metadata": {
        "id": "o-bxyZm5B_Fc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Completar la siguiente celda para graficar el mapa de calor de las correlaciones:"
      ],
      "metadata": {
        "id": "kjsGqTOerOjQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# COMPLETAR\n",
        "cols     = [f\"distance_{part}\" for part in body_parts]\n",
        "corr_mat = ...\n",
        "\n",
        "# Plotear un heatmap de las correlaciones\n",
        "..."
      ],
      "metadata": {
        "id": "K3Bhp3LurMc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (*) Ejercicio 2: Utilizando las features!\n",
        "\n",
        "Las features constituyen un vector de 60 dimensiones que funcionan como descriptores de cada uno de los frames de los videos de los ratones. Como tienen 60 dimensiones es muy dificil graficar algo, por lo que se hace necesario recurrir a t茅cnicas de [reducci贸n dimensional](https://stackabuse.com/dimensionality-reduction-in-python-with-scikit-learn/). Estas t茅cnicas nos permiten reducir la cantidad de datos preservando caracteristicas de lo datos originales. Para ejempliflicar esto utilizaremos una t茅cnica que se conoce como PCA o [Principal Component Analysis](https://jakevdp.github.io/PythonDataScienceHandbook/05.09-principal-component-analysis.html) que busca la direcciones que maximizan la variabilidad de los datos. Veamos un ejemplo."
      ],
      "metadata": {
        "id": "5gxOS1Q1QY3W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Veamos que pasa cuando observamos las features de los frames si nos permiten separar los comportamientos\n",
        "# Para eso creamos esta funci贸n auxiliar que nos devuelve un dataframe con las 60 features mas las anotaciones\n",
        "def load_annotator_features(feat_dict, annotator):\n",
        "    \n",
        "    dict_aux = feat_dict[annotator]\n",
        "    annot_keys = {0:'attack',1: 'investigation',2: 'mount',3:'other'}\n",
        "    \n",
        "    df = pd.DataFrame(dict_aux['features'] , dtype=float)\n",
        "    df['annotations'] = dict_aux['annotations']\n",
        "    df['annotations'] = df['annotations'].map(annot_keys)\n",
        "    \n",
        "    return df\n",
        "  \n",
        "df_features = load_annotator_features(training_features, 'task1/train/mouse001_task1_annotator1')\n",
        "df_features.head()"
      ],
      "metadata": {
        "id": "JnGmYi3z_Uli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "a) Para hacer PCA vamos a necesitar reescalar las columnas de tal manera que queden estandarizadas, pero para eso necesitamos seleccionar las columnas y llevaras a Numpy."
      ],
      "metadata": {
        "id": "3vQNQmIDx18q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# COMPLETAR: seleccionar las columnas correspondientes a los features y guardarla en una variable X como numpy array \n",
        "X = ...\n",
        "print(X.shape)"
      ],
      "metadata": {
        "id": "Ytw2w60otv7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Para que PCA funcione correctamente debemos estandarizar los datos (media 0, desvio 1) y para eso usaremos una funcion que nos provee Scikit Learn\n",
        "scaler = StandardScaler()\n",
        "# Creamos un array nuevo que estar谩 escalado\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "# Verifiquemos (ojo que la media puede no dar exactamente 0 pero si un numero muy peque帽o)\n",
        "#print(X_scaled.mean(axis=0))\n",
        "#print(X_scaled.std(axis=0))"
      ],
      "metadata": {
        "id": "1jgK8LdFHzTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Estamos listos para reducir la dimension y para eso tenemos que crear nuestro objeto que va a reducir la dimension PCA\n",
        "# Indicandole el n煤mero de dimensiones con el cual nos queremos quedar\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "# Creamos un dataframe\n",
        "principal_df = pd.DataFrame(data = X_pca, columns = ['PC1', 'PC2'])\n",
        "principal_df['annotations'] = df_features['annotations']\n",
        "print(principal_df.shape)\n",
        "principal_df.head()"
      ],
      "metadata": {
        "id": "8WCEKoopCej5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Grafiquemos que sucede con la distribuci贸n espacial de las features - puede tardar un poco\n",
        "sns.jointplot(x=principal_df.PC1, y=principal_df.PC2, cmap=\"Blues\", shade=True, kind='kde');"
      ],
      "metadata": {
        "id": "_kyM0iNiIlJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "b) Graficar un scatterplot de las dos componentes asociadas a cada frame agrupando los datos por anotaci贸n. 驴Que conclusiones puede sacar?"
      ],
      "metadata": {
        "id": "97hp8D6CNFO3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# COMPLETAR\n",
        "..."
      ],
      "metadata": {
        "id": "8i3Q9XPBJRUY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "b) Realizar una reducci贸n a 3 dimensiones a los mismos datos y graficarlos utilizando la funci贸n provista por la librer铆a [Plotly](https://plotly.com/python/)."
      ],
      "metadata": {
        "id": "gPOK0T_7HNcB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PCA\n",
        "pca = ...\n",
        "components = ...\n",
        "\n",
        "principal_df = ...\n",
        "principal_df['annotations'] = df_features['annotations']\n",
        "\n",
        "# 3D scatterplot interactivo\n",
        "fig = px.scatter_3d(\n",
        "    components, x=0, y=1, z=2, color=principal_df['annotations'], size=0.1*np.ones(len(X)), opacity = 1,\n",
        "    title='PCA plot in 3D',\n",
        "    labels={'0': 'PC 1', '1': 'PC 2', '2': 'PC 3'},\n",
        "    width=650, height=500\n",
        ")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "tmy4c_jbKpyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "驴Ve una mejor separaci贸n entre los frames de asociados a cada comportamiento?"
      ],
      "metadata": {
        "id": "_6XHK-6uUBcK"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "3PkyhnfN2Os-"
      },
      "source": [
        "# Adicionales: Animaciones de los \n",
        "\n",
        "Esta celda contiene algunas funciones auxiliares que usaremos para crear una animaci贸n de los movimientos del rat贸n. Puedne ignorar el contenido, pero aseg煤rese de ejecutarlo o la siguiente secci贸n no funcionar谩. Esta parte es solo para ilustrar y motivar todas las cosas que podemos hacer con estos datos y python!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "JBTfZHah2Os_",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Funciones auxiliares para los gifs y el raster\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import animation\n",
        "from matplotlib import colors\n",
        "from matplotlib import rc\n",
        "import matplotlib.patches as mpatches\n",
        "\n",
        "rc('animation', html='jshtml')\n",
        "\n",
        "# Note: Image processing may be slow if too many frames are animated.\n",
        "\n",
        "# Plotting constants\n",
        "FRAME_WIDTH_TOP = 1024\n",
        "FRAME_HEIGHT_TOP = 570\n",
        "\n",
        "RESIDENT_COLOR = 'lawngreen'\n",
        "INTRUDER_COLOR = 'skyblue'\n",
        "\n",
        "PLOT_MOUSE_START_END = [(0, 1), (0, 2), (1, 3), (2, 3), (3, 4),\n",
        "                        (3, 5), (4, 6), (5, 6), (1, 2)]\n",
        "class_to_color = {'other': 'white', 'attack' : 'red', 'mount' : 'green',\n",
        "                  'investigation': 'orange'}\n",
        "class_to_number = {s: i for i, s in enumerate(vocab)}\n",
        "number_to_class = {i: s for i, s in enumerate(vocab)}\n",
        "\n",
        "\n",
        "def num_to_text(anno_list):\n",
        "  return np.vectorize(number_to_class.get)(anno_list)\n",
        "\n",
        "\n",
        "def set_figax():\n",
        "  fig = plt.figure(figsize=(6, 4))\n",
        "\n",
        "  img = np.zeros((FRAME_HEIGHT_TOP, FRAME_WIDTH_TOP, 3))\n",
        "\n",
        "  ax = fig.add_subplot(111)\n",
        "  ax.imshow(img)\n",
        "\n",
        "  ax.get_xaxis().set_visible(False)\n",
        "  ax.get_yaxis().set_visible(False)\n",
        "\n",
        "  return fig, ax\n",
        "\n",
        "\n",
        "def plot_mouse(ax, pose, color):\n",
        "  # Draw each keypoint\n",
        "  for j in range(7):\n",
        "    ax.plot(pose[j, 0], pose[j, 1], 'o', color=color, markersize=5)\n",
        "\n",
        "  # Draw a line for each point pair to form the shape of the mouse\n",
        "\n",
        "  for pair in PLOT_MOUSE_START_END:\n",
        "    line_to_plot = pose[pair, :]\n",
        "    ax.plot(line_to_plot[:, 0], line_to_plot[\n",
        "            :, 1], color=color, linewidth=1)\n",
        "\n",
        "\n",
        "def animate_pose_sequence(video_name, keypoint_sequence, start_frame = 0, stop_frame = 100,\n",
        "                          annotation_sequence = None):\n",
        "  # Returns the animation of the keypoint sequence between start frame\n",
        "  # and stop frame. Optionally can display annotations.\n",
        "  seq = keypoint_sequence.transpose((0,1,3,2))\n",
        "\n",
        "  image_list = []\n",
        "\n",
        "  counter = 0\n",
        "  for j in range(start_frame, stop_frame):\n",
        "    if counter%20 == 0:\n",
        "      print(\"Processing frame \", j)\n",
        "    fig, ax = set_figax()\n",
        "    plot_mouse(ax, seq[j, 0, :, :], color=RESIDENT_COLOR)\n",
        "    plot_mouse(ax, seq[j, 1, :, :], color=INTRUDER_COLOR)\n",
        "\n",
        "    if annotation_sequence is not None:\n",
        "      annot = annotation_sequence[j]\n",
        "      annot = number_to_class[annot]\n",
        "      plt.text(50, -20, annot, fontsize=16,\n",
        "               bbox=dict(facecolor=class_to_color[annot], alpha=0.5))\n",
        "\n",
        "    ax.set_title(\n",
        "        video_name + '\\n frame {:03d}.png'.format(j))\n",
        "\n",
        "    ax.axis('off')\n",
        "    fig.tight_layout(pad=0)\n",
        "    ax.margins(0)\n",
        "\n",
        "    fig.canvas.draw()\n",
        "    image_from_plot = np.frombuffer(fig.canvas.tostring_rgb(),\n",
        "                                    dtype=np.uint8)\n",
        "    image_from_plot = image_from_plot.reshape(\n",
        "        fig.canvas.get_width_height()[::-1] + (3,))\n",
        "\n",
        "    image_list.append(image_from_plot)\n",
        "\n",
        "    plt.close()\n",
        "    counter = counter + 1\n",
        "\n",
        "  # Plot animation.\n",
        "  fig = plt.figure()\n",
        "  plt.axis('off')\n",
        "  im = plt.imshow(image_list[0])\n",
        "\n",
        "  def animate(k):\n",
        "      im.set_array(image_list[k])\n",
        "      return im,\n",
        "  ani = animation.FuncAnimation(fig, animate, frames=len(image_list), blit=True)\n",
        "  return ani\n",
        "\n",
        "\n",
        "def plot_behavior_raster(annotation_sequence, start_frame=0,\n",
        "                         stop_frame=100,\n",
        "                         title=\"Behavior Labels\"):\n",
        "  # Plot annotations as a behavior raster\n",
        "\n",
        "  # Map annotations to a number.\n",
        "  annotation_num = []\n",
        "  for item in annotation_sequence[start_frame:stop_frame]:\n",
        "    annotation_num.append(class_to_number[item])\n",
        "\n",
        "  all_classes = list(set(annotation_sequence[start_frame:stop_frame]))\n",
        "\n",
        "  cmap = colors.ListedColormap(['red', 'orange', 'green', 'white'])\n",
        "  bounds=[-0.5, 0.5, 1.5, 2.5, 3.5]\n",
        "  norm = colors.BoundaryNorm(bounds, cmap.N)\n",
        "\n",
        "  height = 200\n",
        "  arr_to_plot = np.repeat(np.array(annotation_num)[:, np.newaxis].transpose(),\n",
        "                                                  height, axis = 0)\n",
        "\n",
        "  fig, ax = plt.subplots(figsize = (16, 3))\n",
        "  ax.imshow(arr_to_plot, interpolation='none',cmap=cmap, norm=norm)\n",
        "\n",
        "  ax.set_yticks([])\n",
        "  ax.set_xlabel('Frame Number')\n",
        "  plt.title(title)\n",
        "\n",
        "  legend_patches = []\n",
        "  for item in all_classes:\n",
        "    legend_patches.append(mpatches.Patch(color=class_to_color[item], label=item))\n",
        "\n",
        "  plt.legend(handles=legend_patches,loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "\n",
        "  plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "WCwVRp5B2OtC"
      },
      "source": [
        "## Visualizando los mivimientos \n",
        "\n",
        "隆Hagamos algunos gifs de nuestra secuencia de muestra para tener una idea de c贸mo se ven los datos sin procesar! Puede cambiar los valores de `start_frame` y `stop_frame` para mirar alrededor. Esto va a demorar un poco."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "VCBrstZl2OtD"
      },
      "outputs": [],
      "source": [
        "keypoint_sequence = single_sequence['keypoints']\n",
        "annotation_sequence = single_sequence['annotations']\n",
        "\n",
        "ani = animate_pose_sequence(sample_sequence_key,\n",
        "                            keypoint_sequence,\n",
        "                            start_frame=5000,\n",
        "                            stop_frame=5100,\n",
        "                            annotation_sequence=annotation_sequence)\n",
        "\n",
        "# Display the animation on colab\n",
        "ani"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "KS2J4EVM2OtF"
      },
      "source": [
        "## Behavior Raster\n",
        "\n",
        "Tambi茅n podemos ver un **Behavior Raster**, que muestra qu茅 comportamiento se anot贸 en cada cuadro de este video."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "DyQpGggv2OtG"
      },
      "outputs": [],
      "source": [
        "annotation_sequence = single_sequence['annotations']\n",
        "text_sequence = num_to_text(annotation_sequence)\n",
        "sns.set(style=\"ticks\")\n",
        "plot_behavior_raster(\n",
        "    text_sequence,\n",
        "    start_frame=0,\n",
        "    stop_frame=len(annotation_sequence)\n",
        "    )"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "51dU2_bT2Os2"
      ],
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernel": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}