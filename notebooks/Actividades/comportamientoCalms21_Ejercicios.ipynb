{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gastonbujia/curso-visualizacion-datos-SAN-2022/blob/main/notebooks/Actividades/comportamientoCalms21_Ejercicios.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "nJdtN4pA2Osf"
      },
      "source": [
        "<h1>\n",
        "CalMS21: Caltech Mouse Social Interaction Dataset 2021 🐁🐀\n",
        "</h1>\n",
        "\n",
        "Esta notebook es una adaptación de la provista por NeuroMatch Academy durante la escuela de [Computational Neuroscience](https://compneuro.neuromatch.io/tutorials/intro.html) curada por Ann Kenedy, que a su vez es una adapatación de la que fuera creada por Dipam Chakraborty y Sharada Mohanty de AIcrowd para el <a href=https://www.aicrowd.com/challenges/multi-agent-behavior-representation-modeling-measurement-and-applications>Multi-Agent Behavior Challenge</a>. La notebook original puede ser encontrada en este [link](https://compneuro.neuromatch.io/projects/behavior/README.html).\n",
        "\n",
        "Este [dataset](https://data.caltech.edu/records/s0vdx-0k302) tiene estimaciones de pose-tracking de ratones interactuando socialmente mediante capturas de video y además cuenta con anotaciones sobre 3 posibles interacciones sociales: *investigacion*, *montar* y *atacar* separada de *otros* compartamientos.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "gRqv3qRZ2Osi"
      },
      "source": [
        "# Imports e instalaciones 📚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "P9eRbsyi2Osl"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Algunas librerias para graficar\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "\n",
        "# Seteamos el estilo\n",
        "sns.set(style=\"darkgrid\")\n",
        "\n",
        "# Reducción de la dimensión y otros\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset CalMS21 📲\n",
        "\n",
        "El dataset **CalMS21** esta hosteado y mantenido por Caltech en https://data.caltech.edu/records/1991. Brevemente, CalMS21 contiene videos y datos anotados de una tarea experimental en la cual se estudia el comportamiento social entre dos ratones, uno que es residente del ambiente y un segundo que es introducido en el mismo. Las interacciones duran aproximadamente unos 10 minutos, son grabadas en un plano cenital y se anotan los comportamientos registrados durante ese tiempo. De los videos se extraen 7 puntos (`keypoints`) para cada ratón estimados por un red neuronal y una confianza de la localización de estos puntos.\n",
        "\n",
        "![](https://images.aicrowd.com/uploads/ckeditor/pictures/332/content_expt_setup_merged.gif)\n",
        "\n",
        "Pueden encontrar [acá](https://www.youtube.com/watch?v=tDmhmasjPeM) un video donde una de las autoras del trabajo nos cuenta sobre este dataset.\n",
        "\n",
        "Dado que el dataset fue construido con el objetivo de probar técnicas de Machine Learning y Deep Learning, hay más de una tarea expermiental, y cada una de ellas contará con un conjunto de *entrenamiento*(`train`) y de *evaluación*(`test`). En esta notebook solo usaremos los datos anotados como la *tarea 1* (`task1`) y el conjunto de entrenamiento. "
      ],
      "metadata": {
        "id": "Bz4q_fR6hj1M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "f1jOx1MS2Osq",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Descarga y unzip\n",
        "import os, requests, zipfile\n",
        "\n",
        "# Descargamos los datos a colab\n",
        "fname = 'task1_classic_classification.zip'\n",
        "url = \"https://data.caltech.edu/records/s0vdx-0k302/files/task1_classic_classification.zip?download=1\"\n",
        "\n",
        "if not os.path.isfile(fname):\n",
        "  try:\n",
        "    r = requests.get(url)\n",
        "  except requests.ConnectionError:\n",
        "    print(\"!!! Failed to download data !!!\")\n",
        "  else:\n",
        "    if r.status_code != requests.codes.ok:\n",
        "      print(\"!!! Failed to download data !!!\")\n",
        "    else:\n",
        "      with open(fname, \"wb\") as fid:\n",
        "        fid.write(r.content)\n",
        "else:\n",
        "  print('Data have already been downloaded!!!')\n",
        "\n",
        "if not os.path.exists('task1_classic_classification'):\n",
        "  # Unzip the file\n",
        "  with zipfile.ZipFile(fname, 'r') as zip_ref:\n",
        "    zip_ref.extractall('.')\n",
        "\n",
        "# Descargamos el parser\n",
        "fname = 'calms21_convert_to_npy.py'\n",
        "url = \"https://data.caltech.edu/records/s0vdx-0k302/files/calms21_convert_to_npy.py?download=1\"\n",
        "\n",
        "if not os.path.isfile(fname):\n",
        "  try:\n",
        "    r = requests.get(url)\n",
        "  except requests.ConnectionError:\n",
        "    print(\"!!! Failed to download data !!!\")\n",
        "  else:\n",
        "    if r.status_code != requests.codes.ok:\n",
        "      print(\"!!! Failed to download data !!!\")\n",
        "    else:\n",
        "      with open(fname, \"wb\") as fid:\n",
        "        fid.write(r.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "RaNAHKSw2Oss"
      },
      "source": [
        "Los archivos del conjunto de datos se almacenan como archivos json. Para facilitar el manejo, primero los convertiremos a archivos .npy usando el script que acabamos de descargar, `calms21_convert_to_npy.py`. La salida de este script es un par de archivos, `calms21_task1_train.npy` y `calms21_task1_test.npy`. Como nosotros no vamos a intentar hacer predicciones con estos datos sino un análisis exploratorio.\n",
        "\n",
        "El repositorio cuenta con un script `calms21_convert_to_npy.py` que permite convertir los datos que estan en formato `JSON` a un formato que nos permite leerlo más facilmente: NumPy Array. En la próxima celda mostramos como utilizar el script pasandole los directorios donde se almacenaron los datos descargados. Si se incluye el indicador `parse_treba` opcional, el script creará los archivos `calms21_task1_train_features.npy` y `calms21_task1_test_features.npy`, que contienen unos 60 *features* creadas con <a href=https://openaccess.thecvf.com/content/CVPR2021/html/Sun_Task_Programming_Learning_Data_Efficient_Behavior_Representations_CVPR_2021_paper.html>Task Programming</a>. Mas adelante también exploraremos esta información.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "NdflG4zj2Osu",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Ejecutar celda para extraer y crear los archivos necesarios\n",
        "!python calms21_convert_to_npy.py  --input_directory '.' --output_directory '.'\n",
        "!python calms21_convert_to_npy.py  --input_directory '.' --output_directory '.' --parse_treba"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "rrk6PPMG2Osw"
      },
      "source": [
        "# Cargamos la data 💾\n",
        "A continuación proveemos una función que permite cargar los datos. Si quieren exploren y traten de entender que es lo que hace."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "u-hmD8z-2Osx"
      },
      "outputs": [],
      "source": [
        "def load_task1_data(data_path, features_path):\n",
        "  \"\"\"\n",
        "  Cargar datos para la tarea 1:\n",
        "       El vocabulario le dice cómo asignar nombres de comportamiento a identificadores de clase;\n",
        "       es el mismo para todas las secuencias en este conjunto de datos.\n",
        "  \"\"\"\n",
        "  data_dict = np.load(data_path, allow_pickle=True).item()\n",
        "  dataset = data_dict['annotator-id_0']\n",
        "  # Obtener una secuencia y sus llaves.\n",
        "  sequence_id = list(data_dict['annotator-id_0'].keys())[0]\n",
        "  vocabulary = data_dict['annotator-id_0'][sequence_id]['metadata']['vocab']\n",
        "  features = np.load(features_path, allow_pickle=True).item()['annotator-id_0']\n",
        "  return dataset, features, vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "pFVJ2jp32Os0"
      },
      "outputs": [],
      "source": [
        "training_data, training_features, vocab = load_task1_data('./calms21_task1_train.npy', './calms21_task1_train_features.npy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "51dU2_bT2Os2"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "Las variables recién creadas `training_data` y `test_data` son diccionarios con una clave para cada **Secuencia** en el conjunto de datos, donde una **Secuencia** es un único ensayo residente-intruso, *hay un total de 70 ensayos*. Cada **Secuencia** contiene los siguientes campos:\n",
        "\n",
        "<ul>\n",
        "<li><b>keypoints</b>: ubicaciones rastreadas de partes del cuerpo en los dos ratones que interactúan. Estos se producen utilizando una red de reloj de arena apilado entrenada en 15,000 marcos etiquetados a mano.\n",
        "<ul>\n",
        "<li>Dimensiones: (n.º de fotogramas) x (ID del ratón) x (coordenada x, y) x (parte del cuerpo).\n",
        "<li>Unidades: píxeles; las coordenadas son relativas a la imagen completa. Las dimensiones de la imagen original son 1024 x 570.\n",
        "</ul>\n",
        "<li><b>scores</b>: estimaciones de confianza para los puntos clave rastreados.\n",
        "<ul>\n",
        "<li>Dimensiones: (n.º de fotogramas) x (ID del ratón) x (parte del cuerpo).\n",
        "<li>Unidades: sin unidades, rango de 0 (confianza más baja) a 1 (confianza más alta).\n",
        "</ul>\n",
        "<li> <b>annotations</b>: ID de comportamientos como un número entero anotado en cada cuadro por un experto en el dominio. Consulte a continuación las asignaciones de ID de comportamiento a nombre de comportamiento.\n",
        "<ul>\n",
        "<li>Dimensiones: (# cuadros) .\n",
        "</ul>\n",
        "<li><b>metadata</b>: los metadatos registrados son annotator_id, que se representa mediante un int, y el vocabulario, que contiene un diccionario que asigna nombres de comportamiento a identificadores enteros en las anotaciones.\n",
        "</ul>\n",
        "\n",
        "El archivo 'taskprog_features' contiene el campo adicional:\n",
        "\n",
        "<ul>\n",
        "<li><b>features</b>: características precalculadas de un modelo entrenado con programación de tareas en los datos de trayectoria del conjunto de videos sin etiqueta CalMS21.\n",
        "<ul>\n",
        "<li>Dimensiones: (n.º de fotogramas) x (dimensión característica = 32).\n",
        "</li>\n",
        "</ul>\n",
        "</ul>\n",
        "\n",
        "![](https://images.aicrowd.com/uploads/ckeditor/pictures/337/content_keypoints_task_1.png)\n",
        "\n",
        "<b>NOTA:</b> para todos los puntos clave, el ratón 0 es el ratón residente (negro) y el ratón 1 es el ratón intruso (blanco). Hay 7 partes del cuerpo rastreadas, ordenadas (nose, left ear, right ear, neck, left hip, right hip, tail base)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "btO01qQ72Os5"
      },
      "source": [
        "## ¿Cómo se ven los datos? 🔍\n",
        "\n",
        "### Resumen de datos\n",
        "\n",
        "Como se describió anteriormente, nuestro conjunto de datos consta de diccionarios de Secuencias y un vocabulario adjunto que nos dice qué comportamiento es resgistrado con que código numérico:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "kKWncUKl2Os6"
      },
      "outputs": [],
      "source": [
        "print(\"Algunas keys: \", list(training_data.keys())[:3])\n",
        "print(\"Vocabulario: \", vocab)\n",
        "print(\"Numero de secuencias: \", len(training_data))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Veamos en que formato esta y que tipos tienen para ver si podemos cargarlo facilmente a Pandas\n",
        "print(f\"Tipo de training data: {type(training_data)}\")\n",
        "print(f\"Tipo de cada dato de un ensayo: {type(training_data['task1/train/mouse001_task1_annotator1'])}\")\n",
        "sequence_names = list(training_data.keys())\n",
        "sample_sequence_key = sequence_names[0]\n",
        "single_sequence = training_data[sample_sequence_key]\n",
        "print(\"Nombre de nuestra secuencia: \", sample_sequence_key)\n",
        "print(\"Keys de la secuencia: \", single_sequence.keys())\n",
        "print(\"Metadata: \", single_sequence['metadata'])\n",
        "print(f\"Numero de frames en una secuencia \\\"{sample_sequence_key}\\\": \", len(single_sequence['annotations']))\n",
        "print(f\"Tamaño de los keypoints de una secuencia \\\"{sample_sequence_key}\\\": \", single_sequence['keypoints'].shape)"
      ],
      "metadata": {
        "id": "4lCWxSNfmlCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "No parece ser tan fácil cargarlo directamente en un DataFrame de Pandas, pero pueden intentarlo en la próxima celda a ver que sucede..."
      ],
      "metadata": {
        "id": "wpx4SfCfGjcs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# COMPLETAR pasarlo directamente a dataframe e imprimirlo\n",
        "df = ...\n",
        "df"
      ],
      "metadata": {
        "id": "KQ6rKrv2m0UV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "¿Tiene sentido cargarlo de esta manera? ¿Que representa cada una de las dimensiones de dataframe cargado de esta manera?"
      ],
      "metadata": {
        "id": "820f87jHrn5B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejercicio 1: Explorando narices 👃"
      ],
      "metadata": {
        "id": "Eamd2nar8FCC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hay varias preguntas que nos pueden interesar a la hora de estudiar este conjunto de datos que tiene que ver con describir las posiciones del cuerpo de los ratones según cada comportamiento. Para este ejercicio nos va a interesar explorar que pasa con las narices de los ratones en cada comportamiento para el primer ensayo."
      ],
      "metadata": {
        "id": "5930lNe7DFPX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Nos vamos para Pandas! 🐼\n",
        "\n",
        "a) Como vimos recién vamos a tener que trabajar un poco el dataset para poder cargarlo en Pandas, por eso primero tienen que completar la función de abajo que procesa uno de los ensayos y nos devuelve toda la información en un unico dataframe. *Hint:* Mirar la función `pd.concat` "
      ],
      "metadata": {
        "id": "ycBfyxN1MHC1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# COMPLETAR esta función para que procese el diccionario de anotaciones en un solo dataframe donde cada columna va a ser una coordenada de un keypoint de cada raton y la confianza\n",
        "def load_annotator_df(data_dict, annotator):\n",
        "    \n",
        "    # vamos a trabajar solo con un ensayo\n",
        "    dict_aux = data_dict[annotator]\n",
        "    # vocabulario\n",
        "    annot_keys = {0:'attack',1: 'investigation',2: 'mount',3:'other'}\n",
        "    # nombre de los keypoints\n",
        "    body_parts = [\"nose\", \"left_ear\", \"right_ear\", \"neck\", \"left_hip\", \"right_hip\", \"tail_base\"]\n",
        "    # una lista donde iremos dejando cada dataframe para luego unirlos en un unico dataframe\n",
        "    df_list = []\n",
        "    \n",
        "    # desagregamos los keypoints en columnas para cada parte trackeada / aclarar aca que podemos tambien usar una lista por comprension / reemplazar por lista\n",
        "    df_list.append(pd.DataFrame(dict_aux['keypoints'][:,0,0,:] , dtype=float, columns=['keypoints_mousse_resident_x_'+i for i in body_parts]))\n",
        "    df_list.append(pd.DataFrame(dict_aux['keypoints'][:,0,1,:] , dtype=float, columns=['keypoints_mousse_resident_y_'+i for i in body_parts]))\n",
        "    df_list.append(pd.DataFrame(dict_aux['keypoints'][:,1,0,:] , dtype=float, columns=['keypoints_mousse_intruder_x_'+i for i in body_parts]))\n",
        "    df_list.append(pd.DataFrame(dict_aux['keypoints'][:,1,1,:] , dtype=float, columns=['keypoints_mousse_intruder_y_'+i for i in body_parts]))\n",
        "    \n",
        "    # desagregamos la confianza de los keypoints \n",
        "    df_list.append(pd.DataFrame(dict_aux['scores'][:,0,:] , dtype=float, columns=['keypoints_mousse_resident_confidence_'+i for i in body_parts]))\n",
        "    df_list.append(pd.DataFrame(dict_aux['scores'][:,1,:] , dtype=float, columns=['keypoints_mousse_intruder_confidence_'+i for i in body_parts]))\n",
        "\n",
        "    # COMPLETAR: crear un único dataframe que sea el resultado de concatenar todos los dataframes de la lista df_list que contenga todas las columnas\n",
        "    df = ...\n",
        "\n",
        "    # COMPLETAR: agregar al dataframe recien creado una columna con la etiqueta correspondiente\n",
        "    df['annotations'] = ...\n",
        "\n",
        "    # COMPLETAR: reemplazar la columna annotations por una que codifique el comportamiento anotado en el vocabulario (miren la funcin map de pandas)\n",
        "    df['annotations'] = ...\n",
        "    \n",
        "    return df"
      ],
      "metadata": {
        "id": "ljzzUU9kp7vo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = load_annotator_df(training_data, 'task1/train/mouse001_task1_annotator1')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "S5cSD0-rNdG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "b) ¿Que comportamientos se registraron para este ensayo?"
      ],
      "metadata": {
        "id": "VLjeto-ORv_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# COMPLETAR Imprimir los valores unicos de la columna annotations\n",
        "..."
      ],
      "metadata": {
        "id": "TfYlknKrRvg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Nuevas columnas\n",
        "\n",
        "Vamos a crear algunas columnas a partir del dataframe cargado que nos permitan caracterizar los comportamientos encontrados en este ensayo y nos basaremos en las distancais de las narices!\n"
      ],
      "metadata": {
        "id": "rc9eiqrGNd-t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "a) Para esto queremos mirar los frames que esten bien estimados, vamos a quedarnos solo con aquellos que tienen una estimación de la nariz más alta que 0.5. Primero seleccionen y grafiquen la distribución de esa confianza para las narices para ambos ratones con un histograma conjunto (o pueden usar dos). *Hint* Pueden usar el parámetro `alpha` que controla la transparencia de las barras."
      ],
      "metadata": {
        "id": "SPUZq9ZbNs6b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# COMPLETAR: Graficar la distribución de la confianza de los keypoints estimate para la nariz de cada raton\n",
        "..."
      ],
      "metadata": {
        "id": "RbyFnnh1OqdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "b) Filtren el dataset en base a que ambas columnas sean mayor al corte `thres`. *Hint* Al tener mas de una condición, dependiendo de que quieran hacer las puede servir el comando [`all`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.all.html)"
      ],
      "metadata": {
        "id": "mQIVP2jaRLEO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# COMPLETAR Crear una mascara con el punto de corte y crear un nuevo dataset a partir de ese\n",
        "cols = [\"keypoints_mousse_resident_confidence_nose\", \"keypoints_mousse_intruder_confidence_nose\"]\n",
        "thres = 0.5\n",
        "df_filter = ...\n",
        "\n",
        "# PREGUNTA: Cuantos datos tiraron?\n",
        "total_frames  = df.shape[0]\n",
        "total_tirados = ...\n",
        "print(f'Descartamos un total del {...}% de frames')"
      ],
      "metadata": {
        "id": "Ucj0mdWm3il-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "c) Ahora si podemos pensar en crear la columna que mida la distancia entre las narices de ambos ratones. Para eso podemos calcular la distancia euclídea entre dos puntos de coordenadas $(x_0,y_0)$ y $(x_1,y_1)$ como:\n",
        "\n",
        "$d=\\sqrt{(x_1-x_0)^2+(y_1-y_0)^2}$\n",
        "\n",
        "\n",
        "Usen las funciones estandar de numpy `sqrt` y `**` para calcularla. PpPpueden usar el atributo `.values` para restar varias columnas entre si. Como adicional vean como pueden calcularla usando la norma del vector restado de las dos narices: [np.linalg.norm](https://numpy.org/doc/stable/reference/generated/numpy.linalg.norm.html)."
      ],
      "metadata": {
        "id": "xdIa29imP7FA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# COMPLETAR: Crear una nueva columna que mida la distancia entre las narices de los ratones\n",
        "df_filter[\"distance_nose\"] = ...\n"
      ],
      "metadata": {
        "id": "DW1ahHd73Rhf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "d) Finalmente graficar en un violinplot la distribución de la columna nueva para cada comportamiento registrado."
      ],
      "metadata": {
        "id": "kppSKwXfSTyd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# COMPLETAR: Graficar para cada comportamiento registrado la distribución de estas distancias (usar un violinplot)\n",
        "..."
      ],
      "metadata": {
        "id": "tkgdonvJSTfC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 Correlaciones de movimiento"
      ],
      "metadata": {
        "id": "vh53RiVoQrCK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por último podemos ver que sucede con la correlación entre las columnas dependiendo de cada comportamiento. Para eso vamos a seleccionar las columnas asociadas a cada punto del cuerpo en el dataframe filtrado y crear nuevas columnas distancia entre ellos y ver si existe correlaciones entre ellas durante la etiqueta `mount`."
      ],
      "metadata": {
        "id": "fi6iKgEFQyVH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vamos a seleccionar las columnas y crear las de distancia \n",
        "body_parts    = [\"nose\", \"left_ear\", \"right_ear\", \"neck\", \"left_hip\", \"right_hip\", \"tail_base\"]\n",
        "cols_intruder = [f\"keypoints_mousse_intruder_{coord}_\"+part for coord in [\"x\",\"y\"] for part in body_parts ] # esto es lo que se conoce como lista por comprehension\n",
        "cols_resident = [f\"keypoints_mousse_resident_{coord}_\"+part for coord in [\"x\",\"y\"] for part in body_parts ]\n",
        "# Hacemos la diferencia coordenada a coordenada\n",
        "diff_array    = df_filter[cols_intruder].values-df_filter[cols_resident].values\n",
        "print(diff_array.shape)\n",
        "\n",
        "# Diff ahora tiene las diferencias coordenada a coordenada, nos falta recorrer las partes del cuerpo y calcular la norma vectorial para obtener las distnacias\n",
        "for i, part in enumerate(body_parts): # enumerate nos devuelve una tupla (i, part) donde el i es la enumeración de los objetos que hay dentro de la lista\n",
        "    df_filter[f\"distance_{part}\"] = np.linalg.norm(diff_array[:,[i,i+7]],axis=1) # 7 porque las columnas son las 7 partes del cuerpo"
      ],
      "metadata": {
        "id": "o-bxyZm5B_Fc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Completar la siguiente celda para graficar el mapa de calor de las correlaciones:"
      ],
      "metadata": {
        "id": "kjsGqTOerOjQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# COMPLETAR\n",
        "cols     = [f\"distance_{part}\" for part in body_parts]\n",
        "corr_mat = ...\n",
        "\n",
        "# Plotear un heatmap de las correlaciones\n",
        "..."
      ],
      "metadata": {
        "id": "K3Bhp3LurMc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (*) Ejercicio 2: Utilizando las features!\n",
        "\n",
        "Las features constituyen un vector de 60 dimensiones que funcionan como descriptores de cada uno de los frames de los videos de los ratones. Como tienen 60 dimensiones es muy dificil graficar algo, por lo que se hace necesario recurrir a técnicas de [reducción dimensional](https://stackabuse.com/dimensionality-reduction-in-python-with-scikit-learn/). Estas técnicas nos permiten reducir la cantidad de datos preservando caracteristicas de lo datos originales. Para ejempliflicar esto utilizaremos una técnica que se conoce como PCA o [Principal Component Analysis](https://jakevdp.github.io/PythonDataScienceHandbook/05.09-principal-component-analysis.html) que busca la direcciones que maximizan la variabilidad de los datos. Veamos un ejemplo."
      ],
      "metadata": {
        "id": "5gxOS1Q1QY3W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Veamos que pasa cuando observamos las features de los frames si nos permiten separar los comportamientos\n",
        "# Para eso creamos esta función auxiliar que nos devuelve un dataframe con las 60 features mas las anotaciones\n",
        "def load_annotator_features(feat_dict, annotator):\n",
        "    \n",
        "    dict_aux = feat_dict[annotator]\n",
        "    annot_keys = {0:'attack',1: 'investigation',2: 'mount',3:'other'}\n",
        "    \n",
        "    df = pd.DataFrame(dict_aux['features'] , dtype=float)\n",
        "    df['annotations'] = dict_aux['annotations']\n",
        "    df['annotations'] = df['annotations'].map(annot_keys)\n",
        "    \n",
        "    return df\n",
        "  \n",
        "df_features = load_annotator_features(training_features, 'task1/train/mouse001_task1_annotator1')\n",
        "df_features.head()"
      ],
      "metadata": {
        "id": "JnGmYi3z_Uli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "a) Para hacer PCA vamos a necesitar reescalar las columnas de tal manera que queden estandarizadas, pero para eso necesitamos seleccionar las columnas y llevaras a Numpy."
      ],
      "metadata": {
        "id": "3vQNQmIDx18q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# COMPLETAR: seleccionar las columnas correspondientes a los features y guardarla en una variable X como numpy array \n",
        "X = ...\n",
        "print(X.shape)"
      ],
      "metadata": {
        "id": "Ytw2w60otv7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Para que PCA funcione correctamente debemos estandarizar los datos (media 0, desvio 1) y para eso usaremos una funcion que nos provee Scikit Learn\n",
        "scaler = StandardScaler()\n",
        "# Creamos un array nuevo que estará escalado\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "# Verifiquemos (ojo que la media puede no dar exactamente 0 pero si un numero muy pequeño)\n",
        "#print(X_scaled.mean(axis=0))\n",
        "#print(X_scaled.std(axis=0))"
      ],
      "metadata": {
        "id": "1jgK8LdFHzTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Estamos listos para reducir la dimension y para eso tenemos que crear nuestro objeto que va a reducir la dimension PCA\n",
        "# Indicandole el número de dimensiones con el cual nos queremos quedar\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "# Creamos un dataframe\n",
        "principal_df = pd.DataFrame(data = X_pca, columns = ['PC1', 'PC2'])\n",
        "principal_df['annotations'] = df_features['annotations']\n",
        "print(principal_df.shape)\n",
        "principal_df.head()"
      ],
      "metadata": {
        "id": "8WCEKoopCej5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Grafiquemos que sucede con la distribución espacial de las features - puede tardar un poco\n",
        "sns.jointplot(x=principal_df.PC1, y=principal_df.PC2, cmap=\"Blues\", shade=True, kind='kde');"
      ],
      "metadata": {
        "id": "_kyM0iNiIlJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "b) Graficar un scatterplot de las dos componentes asociadas a cada frame agrupando los datos por anotación. ¿Que conclusiones puede sacar?"
      ],
      "metadata": {
        "id": "97hp8D6CNFO3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# COMPLETAR\n",
        "..."
      ],
      "metadata": {
        "id": "8i3Q9XPBJRUY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "b) Realizar una reducción a 3 dimensiones a los mismos datos y graficarlos utilizando la función provista por la librería [Plotly](https://plotly.com/python/)."
      ],
      "metadata": {
        "id": "gPOK0T_7HNcB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PCA\n",
        "pca = ...\n",
        "components = ...\n",
        "\n",
        "principal_df = ...\n",
        "principal_df['annotations'] = df_features['annotations']\n",
        "\n",
        "# 3D scatterplot interactivo\n",
        "fig = px.scatter_3d(\n",
        "    components, x=0, y=1, z=2, color=principal_df['annotations'], size=0.1*np.ones(len(X)), opacity = 1,\n",
        "    title='PCA plot in 3D',\n",
        "    labels={'0': 'PC 1', '1': 'PC 2', '2': 'PC 3'},\n",
        "    width=650, height=500\n",
        ")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "tmy4c_jbKpyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "¿Ve una mejor separación entre los frames de asociados a cada comportamiento?"
      ],
      "metadata": {
        "id": "_6XHK-6uUBcK"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "3PkyhnfN2Os-"
      },
      "source": [
        "# Adicionales: Animaciones de los 🐀\n",
        "\n",
        "Esta celda contiene algunas funciones auxiliares que usaremos para crear una animación de los movimientos del ratón. Puedne ignorar el contenido, pero asegúrese de ejecutarlo o la siguiente sección no funcionará. Esta parte es solo para ilustrar y motivar todas las cosas que podemos hacer con estos datos y python!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "JBTfZHah2Os_",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Funciones auxiliares para los gifs y el raster\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import animation\n",
        "from matplotlib import colors\n",
        "from matplotlib import rc\n",
        "import matplotlib.patches as mpatches\n",
        "\n",
        "rc('animation', html='jshtml')\n",
        "\n",
        "# Note: Image processing may be slow if too many frames are animated.\n",
        "\n",
        "# Plotting constants\n",
        "FRAME_WIDTH_TOP = 1024\n",
        "FRAME_HEIGHT_TOP = 570\n",
        "\n",
        "RESIDENT_COLOR = 'lawngreen'\n",
        "INTRUDER_COLOR = 'skyblue'\n",
        "\n",
        "PLOT_MOUSE_START_END = [(0, 1), (0, 2), (1, 3), (2, 3), (3, 4),\n",
        "                        (3, 5), (4, 6), (5, 6), (1, 2)]\n",
        "class_to_color = {'other': 'white', 'attack' : 'red', 'mount' : 'green',\n",
        "                  'investigation': 'orange'}\n",
        "class_to_number = {s: i for i, s in enumerate(vocab)}\n",
        "number_to_class = {i: s for i, s in enumerate(vocab)}\n",
        "\n",
        "\n",
        "def num_to_text(anno_list):\n",
        "  return np.vectorize(number_to_class.get)(anno_list)\n",
        "\n",
        "\n",
        "def set_figax():\n",
        "  fig = plt.figure(figsize=(6, 4))\n",
        "\n",
        "  img = np.zeros((FRAME_HEIGHT_TOP, FRAME_WIDTH_TOP, 3))\n",
        "\n",
        "  ax = fig.add_subplot(111)\n",
        "  ax.imshow(img)\n",
        "\n",
        "  ax.get_xaxis().set_visible(False)\n",
        "  ax.get_yaxis().set_visible(False)\n",
        "\n",
        "  return fig, ax\n",
        "\n",
        "\n",
        "def plot_mouse(ax, pose, color):\n",
        "  # Draw each keypoint\n",
        "  for j in range(7):\n",
        "    ax.plot(pose[j, 0], pose[j, 1], 'o', color=color, markersize=5)\n",
        "\n",
        "  # Draw a line for each point pair to form the shape of the mouse\n",
        "\n",
        "  for pair in PLOT_MOUSE_START_END:\n",
        "    line_to_plot = pose[pair, :]\n",
        "    ax.plot(line_to_plot[:, 0], line_to_plot[\n",
        "            :, 1], color=color, linewidth=1)\n",
        "\n",
        "\n",
        "def animate_pose_sequence(video_name, keypoint_sequence, start_frame = 0, stop_frame = 100,\n",
        "                          annotation_sequence = None):\n",
        "  # Returns the animation of the keypoint sequence between start frame\n",
        "  # and stop frame. Optionally can display annotations.\n",
        "  seq = keypoint_sequence.transpose((0,1,3,2))\n",
        "\n",
        "  image_list = []\n",
        "\n",
        "  counter = 0\n",
        "  for j in range(start_frame, stop_frame):\n",
        "    if counter%20 == 0:\n",
        "      print(\"Processing frame \", j)\n",
        "    fig, ax = set_figax()\n",
        "    plot_mouse(ax, seq[j, 0, :, :], color=RESIDENT_COLOR)\n",
        "    plot_mouse(ax, seq[j, 1, :, :], color=INTRUDER_COLOR)\n",
        "\n",
        "    if annotation_sequence is not None:\n",
        "      annot = annotation_sequence[j]\n",
        "      annot = number_to_class[annot]\n",
        "      plt.text(50, -20, annot, fontsize=16,\n",
        "               bbox=dict(facecolor=class_to_color[annot], alpha=0.5))\n",
        "\n",
        "    ax.set_title(\n",
        "        video_name + '\\n frame {:03d}.png'.format(j))\n",
        "\n",
        "    ax.axis('off')\n",
        "    fig.tight_layout(pad=0)\n",
        "    ax.margins(0)\n",
        "\n",
        "    fig.canvas.draw()\n",
        "    image_from_plot = np.frombuffer(fig.canvas.tostring_rgb(),\n",
        "                                    dtype=np.uint8)\n",
        "    image_from_plot = image_from_plot.reshape(\n",
        "        fig.canvas.get_width_height()[::-1] + (3,))\n",
        "\n",
        "    image_list.append(image_from_plot)\n",
        "\n",
        "    plt.close()\n",
        "    counter = counter + 1\n",
        "\n",
        "  # Plot animation.\n",
        "  fig = plt.figure()\n",
        "  plt.axis('off')\n",
        "  im = plt.imshow(image_list[0])\n",
        "\n",
        "  def animate(k):\n",
        "      im.set_array(image_list[k])\n",
        "      return im,\n",
        "  ani = animation.FuncAnimation(fig, animate, frames=len(image_list), blit=True)\n",
        "  return ani\n",
        "\n",
        "\n",
        "def plot_behavior_raster(annotation_sequence, start_frame=0,\n",
        "                         stop_frame=100,\n",
        "                         title=\"Behavior Labels\"):\n",
        "  # Plot annotations as a behavior raster\n",
        "\n",
        "  # Map annotations to a number.\n",
        "  annotation_num = []\n",
        "  for item in annotation_sequence[start_frame:stop_frame]:\n",
        "    annotation_num.append(class_to_number[item])\n",
        "\n",
        "  all_classes = list(set(annotation_sequence[start_frame:stop_frame]))\n",
        "\n",
        "  cmap = colors.ListedColormap(['red', 'orange', 'green', 'white'])\n",
        "  bounds=[-0.5, 0.5, 1.5, 2.5, 3.5]\n",
        "  norm = colors.BoundaryNorm(bounds, cmap.N)\n",
        "\n",
        "  height = 200\n",
        "  arr_to_plot = np.repeat(np.array(annotation_num)[:, np.newaxis].transpose(),\n",
        "                                                  height, axis = 0)\n",
        "\n",
        "  fig, ax = plt.subplots(figsize = (16, 3))\n",
        "  ax.imshow(arr_to_plot, interpolation='none',cmap=cmap, norm=norm)\n",
        "\n",
        "  ax.set_yticks([])\n",
        "  ax.set_xlabel('Frame Number')\n",
        "  plt.title(title)\n",
        "\n",
        "  legend_patches = []\n",
        "  for item in all_classes:\n",
        "    legend_patches.append(mpatches.Patch(color=class_to_color[item], label=item))\n",
        "\n",
        "  plt.legend(handles=legend_patches,loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "\n",
        "  plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "WCwVRp5B2OtC"
      },
      "source": [
        "## Visualizando los mivimientos 🎥\n",
        "\n",
        "¡Hagamos algunos gifs de nuestra secuencia de muestra para tener una idea de cómo se ven los datos sin procesar! Puede cambiar los valores de `start_frame` y `stop_frame` para mirar alrededor. Esto va a demorar un poco."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "VCBrstZl2OtD"
      },
      "outputs": [],
      "source": [
        "keypoint_sequence = single_sequence['keypoints']\n",
        "annotation_sequence = single_sequence['annotations']\n",
        "\n",
        "ani = animate_pose_sequence(sample_sequence_key,\n",
        "                            keypoint_sequence,\n",
        "                            start_frame=5000,\n",
        "                            stop_frame=5100,\n",
        "                            annotation_sequence=annotation_sequence)\n",
        "\n",
        "# Display the animation on colab\n",
        "ani"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "KS2J4EVM2OtF"
      },
      "source": [
        "## Behavior Raster\n",
        "\n",
        "También podemos ver un **Behavior Raster**, que muestra qué comportamiento se anotó en cada cuadro de este video."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "DyQpGggv2OtG"
      },
      "outputs": [],
      "source": [
        "annotation_sequence = single_sequence['annotations']\n",
        "text_sequence = num_to_text(annotation_sequence)\n",
        "sns.set(style=\"ticks\")\n",
        "plot_behavior_raster(\n",
        "    text_sequence,\n",
        "    start_frame=0,\n",
        "    stop_frame=len(annotation_sequence)\n",
        "    )"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "51dU2_bT2Os2"
      ],
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernel": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}